Origdate <- data[!duplicated(data$AuthNum),c(8,1)] ##creates a table of the original date an auth was received
names(Origdate) <- c("AuthNum","OrigRcvdDate") ##Assign new names for the merge
ProdData <- merge(data,Origdate)  ##lookup Orig date and join by Auth in new column
## The following cleans the data
ProdData$Scheduled <- toupper(ProdData$Scheduled)
ProdData$Cancelled <- toupper(ProdData$Cancelled)
ProdData$UnabletoProcess <- toupper(ProdData$UnabletoProcess)
trim <- function (x) gsub("^\\s+|\\s+$", "", x) ## function that strips spaces and carriage returns
ProdData <- as.data.frame(sapply(ProdData,trim))
ProdData$ReasonUnable <- tolower(ProdData$ReasonUnable)
ProdData$Agent <- tolower(ProdData$Agent)
ProdData$RcvdDate <- as.Date(ProdData$RcvdDate, "%m/%d/%Y")
ProdData$OrigRcvdDate <- as.Date(ProdData$OrigRcvdDate, "%m/%d/%Y")
ProdData$HNAcceptDate <- as.Date(ProdData$HNAcceptDate, "%m/%d/%Y")
rm(list=setdiff(ls(), "ProdData")) ##Removes unneeded files
g <- subset(ProdData, ReasonUnable == "waiting on veteran")[,c(2,14,13,18)]
g[,2] <- tolower(g[,2])
h <- as.data.frame(cast(g, RcvdDate ~ AttemptsConfirmed))
csvFileName <- paste("C:/Users/35148/Documents/R/", "WaitingVet Attempts ",min(h[,1])," to ",max(h[,1]) ,".csv",sep="")
write.csv(h, file=csvFileName) ## Saves file named 'DecayRate minRcvdDate to maxRcvdDate.csv'
q <- subset(ProdData, RcvdDate == max(RcvdDate))
w <- subset(q, OrigRcvdDate <= "2015-09-03")
csvFileName <- paste("C:/Users/35148/Documents/R/", "Old Auths ",min(w[,2])," to ",max(w[,2]) ,".csv",sep="")
write.csv(w, file=csvFileName) ## Saves file named 'DecayRate minRcvdDate to maxRcvdDate.csv'
View(w)
View(q)
View(g)
q <- subset(ProdData, RcvdDate == max(RcvdDate))
View(ProdData)
rm(list=setdiff(ls(), "ProdData")) ##Removes unneeded files
rm(ProdData)
path <- "C:/Users/35148/Documents/R/Daily Files"  ##Full path to the folder where the files are stored
files <- list.files(path=path, pattern="*.csv")  ##Generate a list of all csv files in folder
filelist <- vector("character")  ##Create an empty vector for the names
for(file in files)  ##For each file, read it in while removing spaces (R constraint), add name to filelist
{
k <- which(strsplit(file, "")[[1]]==".")
assign(
gsub(" ","",substr(file, 1, k-1)),
read.csv(paste(path,file,sep="/")))
filenames <- gsub(" ","",substr(file, 1, k-1))
filelist[file] <- filenames
}
rm(list=setdiff(ls(), "ProdData")) ##Removes unneeded files
path <- "C:/Users/35148/Documents/R/Daily Files"  ##Full path to the folder where the files are stored
files <- list.files(path=path, pattern="*.csv")  ##Generate a list of all csv files in folder
filelist <- vector("character")  ##Create an empty vector for the names
for(file in files)  ##For each file, read it in while removing spaces (R constraint), add name to filelist
{
k <- which(strsplit(file, "")[[1]]==".")
assign(
gsub(" ","",substr(file, 1, k-1)),
read.csv(paste(path,file,sep="/")))
filenames <- gsub(" ","",substr(file, 1, k-1))
filelist[file] <- filenames
}
View(`ProgramMasterFile10-2-2015`)
data <- do.call(rbind, lapply(filelist, get, envir = globalenv() )) ##Appends all files to one
rownames(data) <- c(1:length(data[,1]))
names(data) <- c("RcvdDate","Site","Agent","TeamNum","EID","Supervisor","HNAcceptDate","AuthNum","CatofCare","VAMC","Eligibility","StateIn","Scheduled","AttemptsConfirmed","StateOut","Cancelled","UnabletoProcess","ReasonUnable","SecondRvwr")
Origdate <- data[!duplicated(data$AuthNum),c(8,1)] ##creates a table of the original date an auth was received
names(Origdate) <- c("AuthNum","OrigRcvdDate") ##Assign new names for the merge
ProdData <- merge(data,Origdate)  ##lookup Orig date and join by Auth in new column
View(ProdData)
rm(list=setdiff(ls(), "ProdData")) ##Removes unneeded files
path <- "C:/Users/35148/Documents/R/Daily Files"  ##Full path to the folder where the files are stored
files <- list.files(path=path, pattern="*.csv")  ##Generate a list of all csv files in folder
filelist <- vector("character")  ##Create an empty vector for the names
for(file in files)  ##For each file, read it in while removing spaces (R constraint), add name to filelist
{
k <- which(strsplit(file, "")[[1]]==".")
assign(
gsub(" ","",substr(file, 1, k-1)),
read.csv(paste(path,file,sep="/")))
filenames <- gsub(" ","",substr(file, 1, k-1))
filelist[file] <- filenames
}
Sys.sleep(3)
data <- do.call(rbind, lapply(filelist, get, envir = globalenv() )) ##Appends all files to one
rownames(data) <- c(1:length(data[,1]))
names(data) <- c("RcvdDate","Site","Agent","TeamNum","EID","Supervisor","HNAcceptDate","AuthNum","CatofCare","VAMC","Eligibility","StateIn","Scheduled","AttemptsConfirmed","StateOut","Cancelled","UnabletoProcess","ReasonUnable","SecondRvwr")
Sys.sleep(3)
Origdate <- data[!duplicated(data$AuthNum),c(8,1)] ##creates a table of the original date an auth was received
names(Origdate) <- c("AuthNum","OrigRcvdDate") ##Assign new names for the merge
Sys.sleep(3)
ProdData <- merge(data,Origdate)  ##lookup Orig date and join by Auth in new column
## The following cleans the data
ProdData$Scheduled <- toupper(ProdData$Scheduled)
ProdData$Cancelled <- toupper(ProdData$Cancelled)
ProdData$UnabletoProcess <- toupper(ProdData$UnabletoProcess)
trim <- function (x) gsub("^\\s+|\\s+$", "", x) ## function that strips spaces and carriage returns
ProdData <- as.data.frame(sapply(ProdData,trim))
ProdData$ReasonUnable <- tolower(ProdData$ReasonUnable)
ProdData$Agent <- tolower(ProdData$Agent)
ProdData$RcvdDate <- as.Date(ProdData$RcvdDate, "%m/%d/%Y")
ProdData$OrigRcvdDate <- as.Date(ProdData$OrigRcvdDate, "%m/%d/%Y")
ProdData$HNAcceptDate <- as.Date(ProdData$HNAcceptDate, "%m/%d/%Y")
rm(list=setdiff(ls(), "ProdData")) ##Removes unneeded files
View(ProdData)
path <- "C:/Users/35148/Documents/R/Daily Files"  ##Full path to the folder where the files are stored
files <- list.files(path=path, pattern="*.csv")  ##Generate a list of all csv files in folder
filelist <- vector("character")  ##Create an empty vector for the names
for(file in files)  ##For each file, read it in while removing spaces (R constraint), add name to filelist
{
k <- which(strsplit(file, "")[[1]]==".")
assign(
gsub(" ","",substr(file, 1, k-1)),
read.csv(paste(path,file,sep="/")))
filenames <- gsub(" ","",substr(file, 1, k-1))
filelist[file] <- filenames
}
Sys.sleep(3)
data <- do.call(rbind, lapply(filelist, get, envir = globalenv() )) ##Appends all files to one
rownames(data) <- c(1:length(data[,1]))
names(data) <- c("RcvdDate","Site","Agent","TeamNum","EID","Supervisor","HNAcceptDate","AuthNum","CatofCare","VAMC","Eligibility","StateIn","Scheduled","AttemptsConfirmed","StateOut","Cancelled","UnabletoProcess","ReasonUnable","SecondRvwr")
Sys.sleep(3)
Origdate <- data[!duplicated(data$AuthNum),c(8,1)] ##creates a table of the original date an auth was received
names(Origdate) <- c("AuthNum","OrigRcvdDate") ##Assign new names for the merge
Sys.sleep(3)
ProdData <- merge(data,Origdate)  ##lookup Orig date and join by Auth in new column
## The following cleans the data
ProdData$Scheduled <- toupper(ProdData$Scheduled)
ProdData$Cancelled <- toupper(ProdData$Cancelled)
ProdData$UnabletoProcess <- toupper(ProdData$UnabletoProcess)
trim <- function (x) gsub("^\\s+|\\s+$", "", x) ## function that strips spaces and carriage returns
ProdData <- as.data.frame(sapply(ProdData,trim))
ProdData$ReasonUnable <- tolower(ProdData$ReasonUnable)
ProdData$Agent <- tolower(ProdData$Agent)
ProdData$RcvdDate <- as.Date(ProdData$RcvdDate, "%m/%d/%Y")
ProdData$OrigRcvdDate <- as.Date(ProdData$OrigRcvdDate, "%m/%d/%Y")
ProdData$HNAcceptDate <- as.Date(ProdData$HNAcceptDate, "%m/%d/%Y")
rm(list=setdiff(ls(), "ProdData")) ##Removes unneeded files
View(ProdData)
path <- "C:/Users/35148/Documents/R/Daily Files"  ##Full path to the folder where the files are stored
files <- list.files(path=path, pattern="*.csv")  ##Generate a list of all csv files in folder
filelist <- vector("character")  ##Create an empty vector for the names
for(file in files)  ##For each file, read it in while removing spaces (R constraint), add name to filelist
{
k <- which(strsplit(file, "")[[1]]==".")
assign(
gsub(" ","",substr(file, 1, k-1)),
read.csv(paste(path,file,sep="/")))
filenames <- gsub(" ","",substr(file, 1, k-1))
filelist[file] <- filenames
}
data <- do.call(rbind, lapply(filelist, get, envir = globalenv() )) ##Appends all files to one
rownames(data) <- c(1:length(data[,1]))
names(data) <- c("RcvdDate","Site","Agent","TeamNum","EID","Supervisor","HNAcceptDate","AuthNum","CatofCare","VAMC","Eligibility","StateIn","Scheduled","AttemptsConfirmed","StateOut","Cancelled","UnabletoProcess","ReasonUnable","SecondRvwr")
rm(list=setdiff(ls(), "ProdData")) ##Removes unneeded files
rm(ProdData)
path <- "C:/Users/35148/Documents/R/Daily Files"  ##Full path to the folder where the files are stored
files <- list.files(path=path, pattern="*.csv")  ##Generate a list of all csv files in folder
filelist <- vector("character")  ##Create an empty vector for the names
for(file in files)  ##For each file, read it in while removing spaces (R constraint), add name to filelist
{
k <- which(strsplit(file, "")[[1]]==".")
assign(
gsub(" ","",substr(file, 1, k-1)),
read.csv(paste(path,file,sep="/")))
filenames <- gsub(" ","",substr(file, 1, k-1))
filelist[file] <- filenames
}
data <- do.call(rbind, lapply(filelist, get, envir = globalenv() )) ##Appends all files to one
rm(list=setdiff(ls(), "ProdData")) ##Removes unneeded files
path <- "C:/Users/35148/Documents/R/Daily Files"  ##Full path to the folder where the files are stored
files <- list.files(path=path, pattern="*.csv")  ##Generate a list of all csv files in folder
filelist <- vector("character")  ##Create an empty vector for the names
for(file in files)  ##For each file, read it in while removing spaces (R constraint), add name to filelist
{
k <- which(strsplit(file, "")[[1]]==".")
assign(
gsub(" ","",substr(file, 1, k-1)),
read.csv(paste(path,file,sep="/")))
filenames <- gsub(" ","",substr(file, 1, k-1))
filelist[file] <- filenames
}
data <- do.call(rbind, lapply(filelist, get, envir = globalenv() )) ##Appends all files to one
rownames(data) <- c(1:length(data[,1]))
names(data) <- c("RcvdDate","Site","Agent","TeamNum","EID","Supervisor","HNAcceptDate","AuthNum","CatofCare","VAMC","Eligibility","StateIn","Scheduled","AttemptsConfirmed","StateOut","Cancelled","UnabletoProcess","ReasonUnable","SecondRvwr")
Sys.sleep(3)
Origdate <- data[!duplicated(data$AuthNum),c(8,1)] ##creates a table of the original date an auth was received
names(Origdate) <- c("AuthNum","OrigRcvdDate") ##Assign new names for the merge
Sys.sleep(3)
ProdData <- merge(data,Origdate)
## The following cleans the data
ProdData$Scheduled <- toupper(ProdData$Scheduled)
ProdData$Cancelled <- toupper(ProdData$Cancelled)
ProdData$UnabletoProcess <- toupper(ProdData$UnabletoProcess)
trim <- function (x) gsub("^\\s+|\\s+$", "", x) ## function that strips spaces and carriage returns
ProdData <- as.data.frame(sapply(ProdData,trim))
ProdData$ReasonUnable <- tolower(ProdData$ReasonUnable)
ProdData$Agent <- tolower(ProdData$Agent)
ProdData$RcvdDate <- as.Date(ProdData$RcvdDate, "%m/%d/%Y")
ProdData$OrigRcvdDate <- as.Date(ProdData$OrigRcvdDate, "%m/%d/%Y")
ProdData$HNAcceptDate <- as.Date(ProdData$HNAcceptDate, "%m/%d/%Y")
rm(list=setdiff(ls(), "ProdData")) ##Removes unneeded files
View(ProdData)
ProdData[,1] <- trim(ProdData[,1])
trim <- function (x) gsub("^\\s+|\\s+$", "", x) ##
ProdData[,1] <- trim(ProdData[,1])
View(ProdData)
DecayData <- ProdData[,c(1,2,8,20)]  ##Reduces the file to just the columns we need
DecayData$Count <- rep(1,nrow(DecayData))  ##Add a column for counting
DecayRate <- as.data.frame(cast(DecayData, OrigRcvdDate ~ RcvdDate))  ##Create a pivot table
##Change the location where you put the file by changing "C:/Users/35148/Documents/R/": use the same as
##  as setwd() if you want it in the same place
csvFileName <- paste("C:/Users/35148/Documents/R/", "DecayRate ",min(DecayData[,2])," to ",max(DecayData[,2]) ,".csv",sep="")
write.csv(DecayRate, file=csvFileName) ## Saves file named 'DecayRate minRcvdDate to maxRcvdDate.csv'
ReasonsText <- reshape(data=ReasonData[,1:3],idvar = "AuthNum", timevar="RcvdDate",direction="wide") ##Text of Unable to Process Reasons by date
ReasonData <- subset(ProdData[,c(1,2,18,17)], UnabletoProcess == 'Y')
ReasonsText <- reshape(data=ReasonData[,1:3],idvar = "AuthNum", timevar="RcvdDate",direction="wide") ##Text of Unable to Process Reasons by date
textFileName <- paste("C:/Users/35148/Documents/R/", "Reasons Text by Day ",min(ReasonData[,2])," to ",max(ReasonData[,2]) ,".csv",sep="")
write.csv(ReasonsText, file=textFileName) ## Saves file named 'DecayRate minRcvdDate to maxRcvdDate.csv'
g <- subset(ProdData, ReasonUnable == "waiting on veteran")[,c(2,14,13,18)]
g[,2] <- tolower(g[,2])
h <- as.data.frame(cast(g, RcvdDate ~ AttemptsConfirmed))
csvFileName <- paste("C:/Users/35148/Documents/R/", "WaitingVet Attempts ",min(h[,1])," to ",max(h[,1]) ,".csv",sep="")
write.csv(h, file=csvFileName) ## Saves file named 'DecayRate minRcvdDate to maxRcvdDate.csv'
q <- subset(ProdData, RcvdDate == max(RcvdDate))
w <- subset(q, OrigRcvdDate <= "2015-09-05")
csvFileName <- paste("C:/Users/35148/Documents/R/", "Old Auths ",min(w[,2])," to ",max(w[,2]) ,".csv",sep="")
write.csv(w, file=csvFileName) ## Saves file named 'DecayRate minRcvdDate to maxRcvdDate.csv'
View(w)
View(q)
View(q)
min(q[,2])
max(q[,2])
View(q)
csvFileName <- paste("C:/Users/35148/Documents/R/", "Old Auths ",min(w[,2]),".csv",sep="")
write.csv(w, file=csvFileName) ## Saves file named 'DecayRate minRcvdDate to maxRcvdDate.csv'
View(q)
r <- subset(q, ReasonUnable == "missing consult")
View(r)
write.csv(r, "C:/Users/35148/Documents/R/MissingConsult.csv")
rm(list=setdiff(ls(), "ProdData")) ##Removes unneeded files
install.packages("leaflet","htmlwidgets","maps")
rm(ProdData)
install.packages("maps")
install.packages("magrittr")
install.packages("htmlwidgets")
install.packages("leaflet")
install.packages("rvest","scraper")
install.packages("rvest","scrapr")
install.packages("rvest")
top250web <- read_html(http://www.beeradvocate.com/lists/top/)
top250web <- read_html("http://www.beeradvocate.com/lists/top/")
library(magrittr, maps, leaflet, htmlwidgets)
install.packages("htmlwidgets")
library(magrittr, maps, leaflet, htmlwidgets)
library(rvest)
library(magrittr)
library(plyr)
library(stringr)
top250web <- read_html("http://www.beeradvocate.com/lists/top/")
t <- top250web %>%
html_nodes("table") %>%
.[[1]]
##Parse Beer, Brewery, and Style, and add Rank
o <- t %>%
html_nodes("a") %>% ##gives beer, brewery, style
html_text()
BBS <- as.data.frame(matrix(o,nrow=250,ncol=3,byrow = TRUE))
BBS$Rank <- seq(1,250, by =1)
colnames(BBS) <- c("Beer", "Brewery", "Style", "Rank")
##Parse Rank, Beer, Hads remove bang from Hads, Merge with BBS
h <- t %>%
html_nodes("span") %>% ##gives rank, beer, hads
html_text()
h <- h[2:751]
RBH <- as.data.frame(matrix(h,nrow=250,ncol=3,byrow = TRUE))
colnames(RBH) <- c("Rank", "Mush", "Hads")
Merge1 <- merge(BBS, RBH, by.x = "Rank", by.y = "Rank")
Merge1[,6] <- gsub("\\W","",Merge1[,6])
##Parse Beer, Rating, Reviews, merge with Merge1
u <- t %>%
html_nodes("b") %>% ##gives beer, rating, reviews
html_text()
BRR <- as.data.frame(matrix(u,nrow=250,ncol=3,byrow = TRUE))
colnames(BRR) <- c("Beer", "Rating", "Reviews")
Merge2 <- merge(Merge1,BRR, by.x = "Beer", by.y = "Beer")
ABVSplit <- data.frame(String=character(),ABV=character())
for (i in Merge2[,5]) {
if (str_count(i,"/") == 2){
String <- i ##word(i, 1, 2, " / ")
ABV <- word(i, 3, -1, " / ")
} else if ((str_count(i,"/") == 1)&(str_detect(i,'/ [:digit:]') == TRUE)){
String <- i ##word(i, 1, 1, " / ")
ABV <- word(i, 2, -1, " / ")
} else {
String <- i
ABV <- NA
}
df2 <- data.frame(String,ABV)
ABVSplit <- rbind(ABVSplit,df2)
}
Merge3 <- merge(Merge2,ABVSplit, by.x = "Mush", by.y = "String")
Top250 <- Merge3[c(3,2,4,5,9,7,8,6)]
Top250 <- Top250[order(Top250[,1]),]
rm(df2,String,i,Merge1,o,Merge2,Merge3,h,t,ABV,u,BBS,BRR,RBH,ABVSplit)
for(i in c(1,7:ncol(Top250))) {Top250[,i] <- as.numeric(Top250[,i])}
Top250[,6] <- as.numeric(as.character(Top250[,6]))
###This will fix non-American letters back to the original
Top250[,2] <- as.character(Top250[,2])
Top250[,3] <- as.character(Top250[,3])
Encoding(Top250[,2]) <- "UTF-8"
Encoding(Top250[,3]) <- "UTF-8"
rownames(Top250) <- 1:250
##Save the table as a .csv
currentDate <- Sys.Date()
csvFileName <- paste("Top 250 Beers_",currentDate,".csv",sep="")
write.csv(Top250, file=csvFileName, row.names = FALSE)
ggetwd()
getwd()
setwd("C:/Users/35148/Documents/GitHub/BeerMaps")
currentDate <- Sys.Date()
csvFileName <- paste("Top 250 Beers_",currentDate,".csv",sep="")
write.csv(Top250, file=csvFileName, row.names = FALSE)
####create table from website using rvest
library(rvest)
library(magrittr)
library(plyr)
library(stringr)
setwd("C:/Users/Stephen.P.Duffy/Documents/GitHub/BeerMaps")
##Capture HTML From BA Top 250 website and Parse it
top250web <- read_html("http://www.beeradvocate.com/lists/top/")
t <- top250web %>%
html_nodes("table") %>%
.[[1]]
##Parse Beer, Brewery, and Style, and add Rank
o <- t %>%
html_nodes("a") %>% ##gives beer, brewery, style
html_text()
BBS <- as.data.frame(matrix(o,nrow=250,ncol=3,byrow = TRUE))
BBS$Rank <- seq(1,250, by =1)
colnames(BBS) <- c("Beer", "Brewery", "Style", "Rank")
##Parse Rank, Beer, Hads remove bang from Hads, Merge with BBS
h <- t %>%
html_nodes("span") %>% ##gives rank, beer, hads
html_text()
h <- h[2:751]
RBH <- as.data.frame(matrix(h,nrow=250,ncol=3,byrow = TRUE))
colnames(RBH) <- c("Rank", "Mush", "Hads")
Merge1 <- merge(BBS, RBH, by.x = "Rank", by.y = "Rank")
Merge1[,6] <- gsub("\\W","",Merge1[,6])
##Parse Beer, Rating, Reviews, merge with Merge1
u <- t %>%
html_nodes("b") %>% ##gives beer, rating, reviews
html_text()
BRR <- as.data.frame(matrix(u,nrow=250,ncol=3,byrow = TRUE))
colnames(BRR) <- c("Beer", "Rating", "Reviews")
Merge2 <- merge(Merge1,BRR, by.x = "Beer", by.y = "Beer")
###Split apart ABV
ABVSplit <- data.frame(String=character(),ABV=character())
for (i in Merge2[,5]) {
if (str_count(i,"/") == 2){
String <- i ##word(i, 1, 2, " / ")
ABV <- word(i, 3, -1, " / ")
} else if ((str_count(i,"/") == 1)&(str_detect(i,'/ [:digit:]') == TRUE)){
String <- i ##word(i, 1, 1, " / ")
ABV <- word(i, 2, -1, " / ")
} else {
String <- i
ABV <- NA
}
df2 <- data.frame(String,ABV)
ABVSplit <- rbind(ABVSplit,df2)
}
Merge3 <- merge(Merge2,ABVSplit, by.x = "Mush", by.y = "String")
Top250 <- Merge3[c(3,2,4,5,9,7,8,6)]
Top250 <- Top250[order(Top250[,1]),]
rm(df2,String,i,Merge1,o,Merge2,Merge3,h,t,ABV,u,BBS,BRR,RBH,ABVSplit)
###Make Rank, Rating, Reviews and Hads numeric
for(i in c(1,7:ncol(Top250))) {Top250[,i] <- as.numeric(Top250[,i])}
Top250[,6] <- as.numeric(as.character(Top250[,6]))
###This will fix non-American letters back to the original
Top250[,2] <- as.character(Top250[,2])
Top250[,3] <- as.character(Top250[,3])
Encoding(Top250[,2]) <- "UTF-8"
Encoding(Top250[,3]) <- "UTF-8"
rownames(Top250) <- 1:250
##Save the table as a .csv
currentDate <- Sys.Date()
csvFileName <- paste("Top 250 Beers_",currentDate,".csv",sep="")
write.csv(Top250, file=csvFileName, row.names = FALSE)
Breweries <- substr(unique(Top250[,3]),1,20)
Brewaddr <- as.data.frame(matrix(,nrow = 0, ncol = 10))
for (x in Breweries) {
e <- getUrladdr(x)
t <- content(GET(e, accept_xml()))
x <- data.frame(BMid = xpathSApply(t, "//location//id", xmlValue),
name = xpathSApply(t, "//location//name", xmlValue),
status = xpathSApply(t, "//location//status", xmlValue),
street = xpathSApply(t, "//location//street", xmlValue),
city = xpathSApply(t, "//location//city", xmlValue),
state = xpathSApply(t, "//location//state", xmlValue),
zip = xpathSApply(t, "//location//zip", xmlValue),
country = xpathSApply(t, "//location//country", xmlValue),
phone = xpathSApply(t, "//location//phone", xmlValue),
rating= xpathSApply(t, "//location//overall", xmlValue)
)
Brewaddr <- rbind(Brewaddr,x)
rm(x)
}
getUrladdr <- function(brewery,sensor = "false") {
root <- "http://beermapping.com/webservice/locquery/"
bmapi <- "b110d4b01e66ce5aaf3452736aaa1f88"
u <- paste0(root,bmapi,"/",brewery)
return(URLencode(u))
}
Breweries <- substr(unique(Top250[,3]),1,20)
for (x in Breweries) {
e <- getUrladdr(x)
t <- content(GET(e, accept_xml()))
x <- data.frame(BMid = xpathSApply(t, "//location//id", xmlValue),
name = xpathSApply(t, "//location//name", xmlValue),
status = xpathSApply(t, "//location//status", xmlValue),
street = xpathSApply(t, "//location//street", xmlValue),
city = xpathSApply(t, "//location//city", xmlValue),
state = xpathSApply(t, "//location//state", xmlValue),
zip = xpathSApply(t, "//location//zip", xmlValue),
country = xpathSApply(t, "//location//country", xmlValue),
phone = xpathSApply(t, "//location//phone", xmlValue),
rating= xpathSApply(t, "//location//overall", xmlValue)
)
Brewaddr <- rbind(Brewaddr,x)
rm(x)
}
library(httr)
library(XML)
for (x in Breweries) {
e <- getUrladdr(x)
t <- content(GET(e, accept_xml()))
x <- data.frame(BMid = xpathSApply(t, "//location//id", xmlValue),
name = xpathSApply(t, "//location//name", xmlValue),
status = xpathSApply(t, "//location//status", xmlValue),
street = xpathSApply(t, "//location//street", xmlValue),
city = xpathSApply(t, "//location//city", xmlValue),
state = xpathSApply(t, "//location//state", xmlValue),
zip = xpathSApply(t, "//location//zip", xmlValue),
country = xpathSApply(t, "//location//country", xmlValue),
phone = xpathSApply(t, "//location//phone", xmlValue),
rating= xpathSApply(t, "//location//overall", xmlValue)
)
Brewaddr <- rbind(Brewaddr,x)
rm(x)
}
View(Brewaddr)
r <- Brewaddr[which(Brewaddr$BMid == min(df$BMidt)), ]
r <- Brewaddr[which(Brewaddr$BMid == min(Brewaddr$BMidt)), ]
View(Brewaddr)
r <- Brewaddr[which(Brewaddr$BMid == min(Brewaddr$BMid)), ]
Brewaddr[,1] <- as.numeric(as.character(Brewaddr[,1]))
r <- Brewaddr[which(Brewaddr$BMid == min(Brewaddr$BMid)), ]
View(r)
for (x in Breweries) {
e <- getUrladdr(x)
t <- content(GET(e, accept_xml()))
x <- data.frame(BMid = xpathSApply(t, "//location//id", xmlValue),
name = xpathSApply(t, "//location//name", xmlValue),
status = xpathSApply(t, "//location//status", xmlValue),
street = xpathSApply(t, "//location//street", xmlValue),
city = xpathSApply(t, "//location//city", xmlValue),
state = xpathSApply(t, "//location//state", xmlValue),
zip = xpathSApply(t, "//location//zip", xmlValue),
country = xpathSApply(t, "//location//country", xmlValue),
phone = xpathSApply(t, "//location//phone", xmlValue),
rating= xpathSApply(t, "//location//overall", xmlValue)
)
Brewaddr <- rbind(Brewaddr,x)
rm(x)
}
Brewaddr[,1] <- as.numeric(as.character(Brewaddr[,1]))
r <- do.call(rbind, unname(by(Brewaddr, Brewaddr$name, function(x) x[x$BMid == min(x$BMid),])))
View(r)
Brewaddr <- as.data.frame(matrix(,nrow = 0, ncol = 10))
for (x in Breweries) {
e <- getUrladdr(x)
t <- content(GET(e, accept_xml()))
x <- data.frame(BMid = xpathSApply(t, "//location//id", xmlValue),
name = xpathSApply(t, "//location//name", xmlValue),
status = xpathSApply(t, "//location//status", xmlValue),
street = xpathSApply(t, "//location//street", xmlValue),
city = xpathSApply(t, "//location//city", xmlValue),
state = xpathSApply(t, "//location//state", xmlValue),
zip = xpathSApply(t, "//location//zip", xmlValue),
country = xpathSApply(t, "//location//country", xmlValue),
phone = xpathSApply(t, "//location//phone", xmlValue),
rating= xpathSApply(t, "//location//overall", xmlValue)
)
Brewaddr <- rbind(Brewaddr,x)
rm(x)
}
##Then you want to use ids in Brewloc to get lat and long from locmap
Brewaddr[,1] <- as.numeric(as.character(Brewaddr[,1]))
r <- do.call(rbind, unname(by(Brewaddr, Brewaddr$name, function(x) x[x$BMid == min(x$BMid),])))
View(r)
r <- do.call(rbind, unname(by(Brewaddr, Brewaddr$BMid, function(x) x[x$BMid == min(x$BMid),])))
View(Brewaddr)
r <- do.call(rbind, unname(by(Brewaddr, Brewaddr$name, function(x) x[x$BMid == min(x$BMid),])))
getwd()
setwd("C:/Users/35148/Documents/GitHub/RepData_PeerAssessment1")
library(knitr)
knit2html("PA1_temlplate.Rmd")
knit2html("PA1_template.Rmd")
browseURL("PA1_template.html")
knit2html("PA1_template.Rmd")
browseURL("PA1_template.html")
knit2html("PA1_template.Rmd")
browseURL("PA1_template.html")
install.packages("httpuv")
install.packages("catools")
install.packages("caTools")
